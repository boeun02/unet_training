{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPvYsHsHOjv6TewJrFfiWQp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**전에 ver1은 단일 클래스 분류에 컬러 마스크 인식 x**"],"metadata":{"id":"DIYB_PpMH_bO"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnUuqJpgLZSi","executionInfo":{"status":"ok","timestamp":1701130632647,"user_tz":-540,"elapsed":33157,"user":{"displayName":"Spinai0","userId":"03134421830452957416"}},"outputId":"2eb9c9b5-8545-435a-884a-dec31e83efe3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HF4MaviRK0o8","executionInfo":{"status":"ok","timestamp":1701134093594,"user_tz":-540,"elapsed":3454331,"user":{"displayName":"Spinai0","userId":"03134421830452957416"}},"outputId":"74337a28-969a-47f5-b772-7011afb15739"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","73/73 [==============================] - ETA: 0s - loss: 1.3112 - acc: 0.7903\n","Epoch 1: val_loss improved from inf to 1.81021, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r73/73 [==============================] - 187s 2s/step - loss: 1.3112 - acc: 0.7903 - val_loss: 1.8102 - val_acc: 0.8777 - lr: 1.0000e-04\n","Epoch 2/100\n","73/73 [==============================] - ETA: 0s - loss: 0.7857 - acc: 0.8925\n","Epoch 2: val_loss improved from 1.81021 to 1.15850, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 67s 910ms/step - loss: 0.7857 - acc: 0.8925 - val_loss: 1.1585 - val_acc: 0.8788 - lr: 1.0000e-04\n","Epoch 3/100\n","73/73 [==============================] - ETA: 0s - loss: 0.5980 - acc: 0.9110\n","Epoch 3: val_loss improved from 1.15850 to 0.85365, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 904ms/step - loss: 0.5980 - acc: 0.9110 - val_loss: 0.8536 - val_acc: 0.8788 - lr: 1.0000e-04\n","Epoch 4/100\n","73/73 [==============================] - ETA: 0s - loss: 0.4723 - acc: 0.9300\n","Epoch 4: val_loss improved from 0.85365 to 0.75948, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 894ms/step - loss: 0.4723 - acc: 0.9300 - val_loss: 0.7595 - val_acc: 0.8844 - lr: 1.0000e-04\n","Epoch 5/100\n","73/73 [==============================] - ETA: 0s - loss: 0.3611 - acc: 0.9544\n","Epoch 5: val_loss improved from 0.75948 to 0.52619, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.3611 - acc: 0.9544 - val_loss: 0.5262 - val_acc: 0.9235 - lr: 1.0000e-04\n","Epoch 6/100\n","73/73 [==============================] - ETA: 0s - loss: 0.2894 - acc: 0.9634\n","Epoch 6: val_loss improved from 0.52619 to 0.42282, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.2894 - acc: 0.9634 - val_loss: 0.4228 - val_acc: 0.9398 - lr: 1.0000e-04\n","Epoch 7/100\n","73/73 [==============================] - ETA: 0s - loss: 0.2372 - acc: 0.9696\n","Epoch 7: val_loss improved from 0.42282 to 0.34555, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.2372 - acc: 0.9696 - val_loss: 0.3455 - val_acc: 0.9491 - lr: 1.0000e-04\n","Epoch 8/100\n","73/73 [==============================] - ETA: 0s - loss: 0.1971 - acc: 0.9743\n","Epoch 8: val_loss improved from 0.34555 to 0.30278, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 904ms/step - loss: 0.1971 - acc: 0.9743 - val_loss: 0.3028 - val_acc: 0.9526 - lr: 1.0000e-04\n","Epoch 9/100\n","73/73 [==============================] - ETA: 0s - loss: 0.1673 - acc: 0.9769\n","Epoch 9: val_loss improved from 0.30278 to 0.27564, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.1673 - acc: 0.9769 - val_loss: 0.2756 - val_acc: 0.9535 - lr: 1.0000e-04\n","Epoch 10/100\n","73/73 [==============================] - ETA: 0s - loss: 0.1475 - acc: 0.9780\n","Epoch 10: val_loss improved from 0.27564 to 0.23271, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 903ms/step - loss: 0.1475 - acc: 0.9780 - val_loss: 0.2327 - val_acc: 0.9587 - lr: 1.0000e-04\n","Epoch 11/100\n","73/73 [==============================] - ETA: 0s - loss: 0.1252 - acc: 0.9815\n","Epoch 11: val_loss improved from 0.23271 to 0.20203, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 904ms/step - loss: 0.1252 - acc: 0.9815 - val_loss: 0.2020 - val_acc: 0.9615 - lr: 1.0000e-04\n","Epoch 12/100\n","73/73 [==============================] - ETA: 0s - loss: 0.1074 - acc: 0.9838\n","Epoch 12: val_loss improved from 0.20203 to 0.19001, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 67s 906ms/step - loss: 0.1074 - acc: 0.9838 - val_loss: 0.1900 - val_acc: 0.9617 - lr: 1.0000e-04\n","Epoch 13/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0972 - acc: 0.9841\n","Epoch 13: val_loss improved from 0.19001 to 0.17947, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 906ms/step - loss: 0.0972 - acc: 0.9841 - val_loss: 0.1795 - val_acc: 0.9627 - lr: 1.0000e-04\n","Epoch 14/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0895 - acc: 0.9844\n","Epoch 14: val_loss did not improve from 0.17947\n","73/73 [==============================] - 61s 836ms/step - loss: 0.0895 - acc: 0.9844 - val_loss: 0.1829 - val_acc: 0.9632 - lr: 1.0000e-04\n","Epoch 15/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0804 - acc: 0.9854\n","Epoch 15: val_loss improved from 0.17947 to 0.17422, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 900ms/step - loss: 0.0804 - acc: 0.9854 - val_loss: 0.1742 - val_acc: 0.9633 - lr: 1.0000e-04\n","Epoch 16/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0720 - acc: 0.9866\n","Epoch 16: val_loss improved from 0.17422 to 0.16480, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.0720 - acc: 0.9866 - val_loss: 0.1648 - val_acc: 0.9647 - lr: 1.0000e-04\n","Epoch 17/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0671 - acc: 0.9868\n","Epoch 17: val_loss improved from 0.16480 to 0.15617, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.0671 - acc: 0.9868 - val_loss: 0.1562 - val_acc: 0.9641 - lr: 1.0000e-04\n","Epoch 18/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.9863\n","Epoch 18: val_loss improved from 0.15617 to 0.14658, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.0649 - acc: 0.9863 - val_loss: 0.1466 - val_acc: 0.9657 - lr: 1.0000e-04\n","Epoch 19/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0606 - acc: 0.9866\n","Epoch 19: val_loss improved from 0.14658 to 0.14392, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.0606 - acc: 0.9866 - val_loss: 0.1439 - val_acc: 0.9657 - lr: 1.0000e-04\n","Epoch 20/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0555 - acc: 0.9875\n","Epoch 20: val_loss did not improve from 0.14392\n","73/73 [==============================] - 62s 842ms/step - loss: 0.0555 - acc: 0.9875 - val_loss: 0.1544 - val_acc: 0.9639 - lr: 1.0000e-04\n","Epoch 21/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0500 - acc: 0.9887\n","Epoch 21: val_loss did not improve from 0.14392\n","73/73 [==============================] - 61s 836ms/step - loss: 0.0500 - acc: 0.9887 - val_loss: 0.1483 - val_acc: 0.9653 - lr: 1.0000e-04\n","Epoch 22/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.9887\n","Epoch 22: val_loss improved from 0.14392 to 0.14047, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 905ms/step - loss: 0.0480 - acc: 0.9887 - val_loss: 0.1405 - val_acc: 0.9660 - lr: 1.0000e-04\n","Epoch 23/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0508 - acc: 0.9873\n","Epoch 23: val_loss did not improve from 0.14047\n","73/73 [==============================] - 62s 838ms/step - loss: 0.0508 - acc: 0.9873 - val_loss: 0.1943 - val_acc: 0.9563 - lr: 1.0000e-04\n","Epoch 24/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.9859\n","Epoch 24: val_loss did not improve from 0.14047\n","73/73 [==============================] - 61s 837ms/step - loss: 0.0539 - acc: 0.9859 - val_loss: 0.1646 - val_acc: 0.9605 - lr: 1.0000e-04\n","Epoch 25/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0465 - acc: 0.9879\n","Epoch 25: val_loss improved from 0.14047 to 0.13465, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 67s 909ms/step - loss: 0.0465 - acc: 0.9879 - val_loss: 0.1346 - val_acc: 0.9666 - lr: 1.0000e-04\n","Epoch 26/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0411 - acc: 0.9892\n","Epoch 26: val_loss improved from 0.13465 to 0.13101, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 902ms/step - loss: 0.0411 - acc: 0.9892 - val_loss: 0.1310 - val_acc: 0.9681 - lr: 1.0000e-04\n","Epoch 27/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9897\n","Epoch 27: val_loss did not improve from 0.13101\n","73/73 [==============================] - 62s 838ms/step - loss: 0.0386 - acc: 0.9897 - val_loss: 0.1356 - val_acc: 0.9675 - lr: 1.0000e-04\n","Epoch 28/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9892\n","Epoch 28: val_loss did not improve from 0.13101\n","73/73 [==============================] - 61s 836ms/step - loss: 0.0386 - acc: 0.9892 - val_loss: 0.1388 - val_acc: 0.9664 - lr: 1.0000e-04\n","Epoch 29/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0382 - acc: 0.9891\n","Epoch 29: val_loss did not improve from 0.13101\n","73/73 [==============================] - 62s 844ms/step - loss: 0.0382 - acc: 0.9891 - val_loss: 0.1330 - val_acc: 0.9671 - lr: 1.0000e-04\n","Epoch 30/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0372 - acc: 0.9891\n","Epoch 30: val_loss did not improve from 0.13101\n","73/73 [==============================] - 61s 838ms/step - loss: 0.0372 - acc: 0.9891 - val_loss: 0.1350 - val_acc: 0.9658 - lr: 1.0000e-04\n","Epoch 31/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9901\n","Epoch 31: val_loss improved from 0.13101 to 0.12319, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 898ms/step - loss: 0.0344 - acc: 0.9901 - val_loss: 0.1232 - val_acc: 0.9693 - lr: 1.0000e-05\n","Epoch 32/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0310 - acc: 0.9914\n","Epoch 32: val_loss improved from 0.12319 to 0.12268, saving model to /content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug/unet-non-aug.h5\n","73/73 [==============================] - 66s 900ms/step - loss: 0.0310 - acc: 0.9914 - val_loss: 0.1227 - val_acc: 0.9695 - lr: 1.0000e-05\n","Epoch 33/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0298 - acc: 0.9919\n","Epoch 33: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 842ms/step - loss: 0.0298 - acc: 0.9919 - val_loss: 0.1234 - val_acc: 0.9696 - lr: 1.0000e-05\n","Epoch 34/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0289 - acc: 0.9922\n","Epoch 34: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 840ms/step - loss: 0.0289 - acc: 0.9922 - val_loss: 0.1245 - val_acc: 0.9696 - lr: 1.0000e-05\n","Epoch 35/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0281 - acc: 0.9925\n","Epoch 35: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 838ms/step - loss: 0.0281 - acc: 0.9925 - val_loss: 0.1258 - val_acc: 0.9696 - lr: 1.0000e-05\n","Epoch 36/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0274 - acc: 0.9928\n","Epoch 36: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 835ms/step - loss: 0.0274 - acc: 0.9928 - val_loss: 0.1271 - val_acc: 0.9696 - lr: 1.0000e-05\n","Epoch 37/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0268 - acc: 0.9931\n","Epoch 37: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 841ms/step - loss: 0.0268 - acc: 0.9931 - val_loss: 0.1292 - val_acc: 0.9694 - lr: 1.0000e-06\n","Epoch 38/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.9934\n","Epoch 38: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 839ms/step - loss: 0.0262 - acc: 0.9934 - val_loss: 0.1304 - val_acc: 0.9692 - lr: 1.0000e-06\n","Epoch 39/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9934\n","Epoch 39: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 839ms/step - loss: 0.0261 - acc: 0.9934 - val_loss: 0.1310 - val_acc: 0.9692 - lr: 1.0000e-06\n","Epoch 40/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0260 - acc: 0.9935\n","Epoch 40: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 842ms/step - loss: 0.0260 - acc: 0.9935 - val_loss: 0.1313 - val_acc: 0.9692 - lr: 1.0000e-06\n","Epoch 41/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9935\n","Epoch 41: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 839ms/step - loss: 0.0259 - acc: 0.9935 - val_loss: 0.1314 - val_acc: 0.9692 - lr: 1.0000e-07\n","Epoch 42/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0259 - acc: 0.9936\n","Epoch 42: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 839ms/step - loss: 0.0259 - acc: 0.9936 - val_loss: 0.1315 - val_acc: 0.9691 - lr: 1.0000e-07\n","Epoch 43/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 43: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 843ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1316 - val_acc: 0.9691 - lr: 1.0000e-07\n","Epoch 44/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 44: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 836ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1316 - val_acc: 0.9691 - lr: 1.0000e-07\n","Epoch 45/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 45: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 837ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-08\n","Epoch 46/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 46: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 842ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-08\n","Epoch 47/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 47: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 841ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-08\n","Epoch 48/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 48: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 838ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-08\n","Epoch 49/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 49: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 840ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-09\n","Epoch 50/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 50: val_loss did not improve from 0.12268\n","73/73 [==============================] - 62s 841ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-09\n","Epoch 51/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 51: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 837ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-09\n","Epoch 52/100\n","73/73 [==============================] - ETA: 0s - loss: 0.0258 - acc: 0.9936\n","Epoch 52: val_loss did not improve from 0.12268\n","73/73 [==============================] - 61s 839ms/step - loss: 0.0258 - acc: 0.9936 - val_loss: 0.1317 - val_acc: 0.9691 - lr: 1.0000e-09\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7875a2105f30>"]},"metadata":{},"execution_count":2}],"source":["import os\n","import numpy as np\n","import cv2\n","from glob import glob\n","import tensorflow as tf\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input, Dropout, Lambda\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n"]},{"cell_type":"code","source":["# GPU 설정\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","    except RuntimeError as e:\n","        print(e)"],"metadata":{"id":"E8yFf54wIOix"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 고정된 시드 값\n","os.environ[\"PYTHONHASHSEED\"] = str(42)\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"metadata":{"id":"_YyTSrMTpocC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 하이퍼파라미터 설정\n","batch_size = 8\n","lr = 1e-4\n","epochs = 100\n","height = 384\n","width = 256\n","num_classes = 13"],"metadata":{"id":"2huf5_AFIlYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 경로\n","dataset_path = r\"/content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug\"\n","\n","# 모델 및 로그 파일 경로\n","files_dir = os.path.join(r\"/content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug\", \"non-aug\")\n","model_file = os.path.join(r\"/content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug\", \"unet-non-aug.h5\")\n","log_file = os.path.join(r\"/content/drive/MyDrive/006_BMS2/0002_latxray_training/dataset/non-aug\", \"log-non-aug.csv\")"],"metadata":{"id":"u1LRDwY5Iomq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디렉터리 생성 함수\n","def create_dir(path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)"],"metadata":{"id":"9YmLYVqZI5Vq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_dir(files_dir)"],"metadata":{"id":"mxCVDIVXI8RQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convolution Block\n","def conv_block(inputs, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    return x"],"metadata":{"id":"PaVvaV-TI-ba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoder Block\n","def encoder_block(inputs, num_filters):\n","    x = conv_block(inputs, num_filters)\n","    p = MaxPool2D((2, 2))(x)\n","    return x, p"],"metadata":{"id":"9UI0TwkPJEZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decoder Block\n","def decoder_block(inputs, skip, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n","    # Conv2DTranspose의 출력 크기 조정\n","    x = tf.image.resize(x, [tf.shape(skip)[1], tf.shape(skip)[2]], method='nearest')\n","    x = Concatenate()([x, skip])\n","    x = conv_block(x, num_filters)\n","    return x"],"metadata":{"id":"fuxiYiaGJLw7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# U-Net Model\n","def build_unet(input_shape):\n","    inputs = Input(input_shape)\n","\n","    # Encoder\n","    s1, p1 = encoder_block(inputs, 64)\n","    s2, p2 = encoder_block(p1, 128)\n","    s3, p3 = encoder_block(p2, 256)\n","    s4, p4 = encoder_block(p3, 512)\n","\n","    # Bridge\n","    b1 = conv_block(p4, 1024)\n","\n","    # Decoder\n","    d1 = decoder_block(b1, s4, 512)\n","    d2 = decoder_block(d1, s3, 256)\n","    d3 = decoder_block(d2, s2, 128)\n","    d4 = decoder_block(d3, s1, 64)\n","\n","    # Output\n","    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n","    model = Model(inputs, outputs, name=\"UNET\")\n","    return model"],"metadata":{"id":"xVo2GGkOJOP6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Loading and Preprocessing\n","def load_data(path):\n","    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n","    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*.png\")))\n","\n","    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n","    test_y = sorted(glob(os.path.join(path, \"test\", \"masks\", \"*.png\")))\n","    return (train_x, train_y), (test_x, test_y)"],"metadata":{"id":"m05vymDdJR1B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_image(path):\n","    # path.numpy().decode() 대신에 바로 경로를 사용\n","    x = cv2.imread(path.decode(), cv2.IMREAD_COLOR)\n","    x = cv2.resize(x, (width, height))\n","    x = x / 255.0\n","    x = x.astype(np.float32) # 데이터 타입을 float32로 변경\n","    return x"],"metadata":{"id":"82_xtO9MJWsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_mask(path):\n","    path = path.decode()\n","    mask = cv2.imread(path, cv2.IMREAD_COLOR)\n","    mask = cv2.resize(mask, (width, height))\n","    mask = mask.astype(np.uint8)  # 정수형으로 변환\n","\n","    # 클래스별 색상 정의\n","    class_colors = {\n","        (255, 0, 0): 0,  # S1\n","        (0, 255, 0): 1,  # L5\n","        (0, 0, 255): 2,  # L4\n","        (255, 255, 0): 3,  # L3\n","        (255, 0, 255): 4,  # L2\n","        (0, 255, 255): 5,  # L1\n","        (100, 100, 255): 6,  # T12\n","        (100, 255, 100): 7,  # T11\n","        (255, 100, 100): 8,  # T10\n","        (100, 255, 255): 9,  # T9\n","        (255, 100, 255): 10, # latLSpine\n","        (255, 255, 100): 11, # latSacrum\n","        (100, 100, 100): 12  # Aorticcalcification\n","    }\n","\n","    # 색상을 클래스 인덱스로 변환\n","    class_mask = np.zeros((mask.shape[0], mask.shape[1]), dtype=np.int32)\n","    for color, class_idx in class_colors.items():\n","        equality = np.equal(mask, color)\n","        class_mask[np.all(equality, axis=-1)] = class_idx\n","\n","    class_mask = class_mask.astype(np.float32) #  여기서 데이터 타입을 float32로 설정\n","    class_mask = np.expand_dims(class_mask, axis=-1)  # 새로운 차원 추가\n","    return class_mask"],"metadata":{"id":"hpR8BpkfJZvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_parse(x, y):\n","    def _parse(x, y):\n","        x = read_image(x)\n","        y = read_mask(y)\n","        return x, y\n","\n","    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n","    x.set_shape([height, width, 3])\n","    y.set_shape([height, width, 1])\n","    return x, y"],"metadata":{"id":"iP23C808JgDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tf_dataset(x, y, batch=8):\n","    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","    return dataset"],"metadata":{"id":"kn01jfmOJlPd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Load and Dataset Creation\n","(train_x, train_y), (test_x, test_y) = load_data(dataset_path)\n","train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n","test_dataset = tf_dataset(test_x, test_y, batch=batch_size)"],"metadata":{"id":"8wpz3hcNJpqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Build and Compile\n","model = build_unet((height, width, 3))\n","opt = tf.keras.optimizers.Adam(lr)\n","model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"acc\"])"],"metadata":{"id":"eFq05bQLJtsi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Callback Functions and Model Training\n","callbacks = [\n","    ModelCheckpoint(model_file, verbose=1, save_best_only=True, monitor='val_loss'),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4),\n","    CSVLogger(log_file),\n","    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n","]"],"metadata":{"id":"oBgYapa2J3Sr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Training\n","model.fit(\n","    train_dataset,\n","    validation_data=test_dataset,\n","    epochs=epochs,\n","    callbacks=callbacks\n",")"],"metadata":{"id":"InR7OirGJ6FK"},"execution_count":null,"outputs":[]}]}